{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP8pS4zMhDngDgTw1QN06t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alyssa-ckt/Python-Projects/blob/main/AI_Market_Research_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icfCs_lMdLOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "147f3c25-ce44-425c-86cc-e86d3a83c086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install -qU langchain-community wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-google-genai"
      ],
      "metadata": {
        "id": "kp0GnXasgu_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea7256a-f9ee-434a-df5e-47f0dc7ff354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m61.4/66.5 kB\u001b[0m \u001b[31m142.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-groq"
      ],
      "metadata": {
        "id": "hgAxFc2_Tk7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40c86299-ff69-47fd-953e-5caaf7ad595f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import pandas as pd\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "Fu1eEqhxlswk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import WikipediaRetriever\n",
        "\n",
        "retriever = WikipediaRetriever(top_k_results = 10)"
      ],
      "metadata": {
        "id": "SQc1EsXIfB3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from google.colab import userdata\n",
        "os.environ['GROQ_API_KEY'] = userdata.get('llama')"
      ],
      "metadata": {
        "id": "N0M99WYyUztz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "AlxKwt9BhbQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Configure your key\n",
        "genai.configure(api_key=\"AIzaSyAlrGmKJqUZeOajTlojoHce8hVteVrVMYE\")\n",
        "\n",
        "print(\"Available models for your key:\")\n",
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(f\"- {m.name}\")"
      ],
      "metadata": {
        "id": "mPOkVKjHHq_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pacakges\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# select model\n",
        "model = \"models/gemini-3-flash-preview\"\n",
        "\n",
        "# initialize model\n",
        "max_output_tokens = 100\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=model,\n",
        "    temperature=0,\n",
        "    max_output_tokens=max_output_tokens,\n",
        ")"
      ],
      "metadata": {
        "id": "WpbOI4yggmxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    model_name=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0.5,\n",
        "    max_tokens=1200,\n",
        "    max_retries=2\n",
        ")"
      ],
      "metadata": {
        "id": "ALGqfiHRVDsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"solar panels\"\n",
        "\n",
        "# 1. Fetch the documents\n",
        "docs = retriever.invoke(query)\n",
        "\n",
        "# 2. Extract and print (and store for the next step)\n",
        "sources_list = []\n",
        "\n",
        "if not docs:\n",
        "    print(\"No Wikipedia results found.\")\n",
        "else:\n",
        "    for i, doc in enumerate(docs, start=1):\n",
        "        title = doc.metadata.get('title', 'Unknown Title')\n",
        "        url = doc.metadata.get('source', 'No URL available')\n",
        "\n",
        "        sources_list.append(f\"Title: {title}\\nURL: {url}\\nContent: {doc.page_content[:500]}...\") # Get a snippet\n",
        "\n",
        "        print(f\"{i}. {title}\")\n",
        "        print(f\"   URL: {url}\\n\")\n",
        "\n",
        "# 3. Join them for your AI prompt\n",
        "context_for_ai = \"\\n\\n\".join(sources_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPGRNJ8ot-3t",
        "outputId": "f9cad4d2-35cc-4de4-ce5d-7ac1a0196df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Solar panel\n",
            "   URL: https://en.wikipedia.org/wiki/Solar_panel\n",
            "\n",
            "2. Solar panels on spacecraft\n",
            "   URL: https://en.wikipedia.org/wiki/Solar_panels_on_spacecraft\n",
            "\n",
            "3. Agrivoltaics\n",
            "   URL: https://en.wikipedia.org/wiki/Agrivoltaics\n",
            "\n",
            "4. Solar energy\n",
            "   URL: https://en.wikipedia.org/wiki/Solar_energy\n",
            "\n",
            "5. Photovoltaics\n",
            "   URL: https://en.wikipedia.org/wiki/Photovoltaics\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import WikipediaRetriever\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import re\n",
        "\n",
        "def generate_industry_report():\n",
        "  while True:\n",
        "    user_input = input(\"\\nEnter industry: \").strip()\n",
        "\n",
        "    if len(user_input) < 3:\n",
        "      print(\"[INPUT ERROR] Please enter a valid industry name (e.g., 'Healthcare', 'Cosmetics').\")\n",
        "      continue\n",
        "\n",
        "    if not user_input or not re.search(r\"[a-zA-Z]\", user_input):\n",
        "      print(\"[INPUT REQUIRED] Please enter a valid industry (e.g., 'Healthcare', 'Semiconductors').\")\n",
        "      return\n",
        "\n",
        "    industry_check_prompt = f\"\"\"\n",
        "    You are an input validator.\n",
        "\n",
        "    TASK:\n",
        "    Determine whether the \"{user_input}\" refers to a BUSINESS INDUSTRY, SECTOR, or MARKET.\n",
        "\n",
        "    Respond with EXACTLY one word:\n",
        "    VALID or INVALID\n",
        "\n",
        "    Then give a one sentence reason if it is INVALID\n",
        "    \"\"\"\n",
        "    classification_raw = llm.invoke(industry_check_prompt).content.strip()\n",
        "    classification = classification_raw.split()[0].upper()\n",
        "\n",
        "    if classification == \"VALID\":\n",
        "        break\n",
        "    else:\n",
        "        print(f\"'{user_input}' does not appear to be a valid industry.\")\n",
        "        reason = classification_raw.replace(\"INVALID\", \"\").strip()\n",
        "        if reason:\n",
        "            print(f\"Reason: {reason}\")\n",
        "\n",
        "  # --- STEP 1: MULTI-QUERY EXPANSION ---\n",
        "  setup_prompt = f\"\"\"\n",
        "  You are a research query planner for a market research assistant.\n",
        "\n",
        "  INDUSTRY:\n",
        "  \"{user_input}\"\n",
        "\n",
        "  OBJECTIVE:\n",
        "  Generate Wikipedia search queries that will retrieve pages useful for producing\n",
        "  a business-focused industry research report.\n",
        "\n",
        "  STRICT RULES:\n",
        "  - Every query MUST explicitly refer to the \"{user_input}\" industry or a very close synonym.\n",
        "  - Do NOT generate queries for adjacent or parent industries unless they explicitly include \"{user_input}\".\n",
        "  - Prefer canonical Wikipedia article titles over descriptive phrases.\n",
        "  - Avoid geography-only, company-only, or historical-only queries.\n",
        "  - Do NOT include future predictions or forecasts unless Wikipedia commonly covers them.\n",
        "\n",
        "  TASK:\n",
        "  Generate exactly 5 Wikipedia search queries, each targeting a distinct business dimension:\n",
        "\n",
        "  1. Industry definition and scope\n",
        "  2. Market structure and value chain\n",
        "  3. Competitive landscape and key players\n",
        "  4. Economic significance or market size (if available)\n",
        "  5. Industry trends, regulation, or structural change\n",
        "\n",
        "  FORMAT (EXACT):\n",
        "  QUERIES:\n",
        "  - <query 1>\n",
        "  - <query 2>\n",
        "  - <query 3>\n",
        "  - <query 4>\n",
        "  - <query 5>\n",
        "  \"\"\"\n",
        "\n",
        "  setup_data = llm.invoke(setup_prompt).content.strip()\n",
        "\n",
        "  queries = [\n",
        "      q.strip(\"- \").strip()\n",
        "      for q in setup_data.splitlines()\n",
        "      if q.strip().startswith(\"-\")\n",
        "  ]\n",
        "\n",
        "  retriever = WikipediaRetriever(load_max_docs=17, lang=\"en\")\n",
        "\n",
        "  all_docs = []\n",
        "  for q in queries:\n",
        "      all_docs.extend(retriever.invoke(q))\n",
        "\n",
        "  # Deduplicate\n",
        "  unique_docs = {doc.metadata[\"title\"]: doc for doc in all_docs}\n",
        "  raw_docs = list(unique_docs.values())\n",
        "\n",
        "  if not raw_docs:\n",
        "      print(\"No results found.\")\n",
        "      return\n",
        "\n",
        "  # --- STEP 2: BOUNCER ---\n",
        "  titles_list = [doc.metadata[\"title\"] for doc in raw_docs]\n",
        "\n",
        "  bouncer_prompt = f\"\"\"\n",
        "  You are a source quality filter for a business market research tool.\n",
        "\n",
        "  INDUSTRY:\n",
        "  \"{user_input}\"\n",
        "\n",
        "  TASK:\n",
        "  From the list below, select only 5 Wikipedia article titles that:\n",
        "  - Describe the \"{user_input}\" industry as a whole\n",
        "  - Are useful for business or market analysis\n",
        "  - NOT country-specific, company-specific, or historical-only\n",
        "\n",
        "  RETURN FORMAT:\n",
        "  - Return ONLY the exact titles, separated by commas.\n",
        "  - Do NOT explain your reasoning.\n",
        "\n",
        "  CANDIDATE TITLES:\n",
        "  {titles_list}\n",
        "  \"\"\"\n",
        "\n",
        "  verified_titles = [\n",
        "      t.strip().lower()\n",
        "      for t in llm.invoke(bouncer_prompt).content.split(\",\")\n",
        "  ]\n",
        "\n",
        "  final_docs = [\n",
        "      doc for doc in raw_docs\n",
        "      if any(v in doc.metadata[\"title\"].lower() for v in verified_titles)\n",
        "  ]\n",
        "\n",
        "  # Deduplicate by title first\n",
        "  seen = set()\n",
        "  deduped_docs = []\n",
        "\n",
        "  for doc in final_docs:\n",
        "      title = doc.metadata[\"title\"]\n",
        "      if title not in seen:\n",
        "          seen.add(title)\n",
        "          deduped_docs.append(doc)\n",
        "\n",
        "  final_docs = deduped_docs[:5]\n",
        "\n",
        "  final_docs = [doc for doc in raw_docs if any(v in doc.metadata[\"title\"].lower() for v in verified_titles)]\n",
        "  seen_titles = {doc.metadata[\"title\"] for doc in final_docs}\n",
        "\n",
        "  # Fill missing slots\n",
        "  if len(final_docs) < 5:\n",
        "      for doc in raw_docs:\n",
        "          title = doc.metadata[\"title\"]\n",
        "          if title not in seen_titles:\n",
        "              final_docs.append(doc)\n",
        "              seen_titles.add(title)\n",
        "          if len(final_docs) == 5:\n",
        "              break\n",
        "\n",
        "          # Search each broad query and add results\n",
        "    # for q in broad_queries:\n",
        "    #     docs = retriever.invoke(q)\n",
        "    #     for doc in docs:\n",
        "    #         title = doc.metadata[\"title\"]\n",
        "    #         # Add only if it's new and contains the industry keyword\n",
        "    #         if title not in [d.metadata[\"title\"] for d in final_docs]:\n",
        "    #             if user_input.lower() in title.lower():  # strict relevance\n",
        "    #                 final_docs.append(doc)\n",
        "\n",
        "    # Cap at 5 sources\n",
        "    # final_docs = final_docs[:5]\n",
        "\n",
        "  if not final_docs:\n",
        "      print(\"\\n[!] DATA GAP DETECTED\")\n",
        "      print(f\"I couldn't find specific business market data for '{user_input}' on Wikipedia.\")\n",
        "      print(\"Please provide more details (e.g., 'Automotive manufacturing' instead of just 'Cars') or try a different sector.\")\n",
        "      return # This stops the function immediately so no report is generated\n",
        "\n",
        "  # --- STEP 3: Context Preparation & Report ---\n",
        "  context_text = \"\"\n",
        "  print(\"-\" * 15 + \" VERIFIED SOURCES \" + \"-\" * 15)\n",
        "\n",
        "  for i, doc in enumerate(final_docs, 1):\n",
        "      title = doc.metadata.get('title')\n",
        "      url = doc.metadata.get('source')\n",
        "      print(f\"{i}. {title}\\n   URL: {url}\")\n",
        "\n",
        "      # Build the context block for the report\n",
        "      context_text += (\n",
        "          f\"[SOURCE {i}]\\n\"\n",
        "          f\"TITLE: {title}\\n\"\n",
        "          f\"URL: {url}\\n\"\n",
        "          f\"CONTENT:\\n{doc.page_content[:1500]}\\n\\n\"\n",
        "          )\n",
        "\n",
        "  # Final Generation\n",
        "  report_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "  ROLE:\n",
        "  You are a Market Research Assistant supporting business analysts at a large corporation.\n",
        "\n",
        "  OBJECTIVE:\n",
        "  Produce a concise, decision-oriented industry briefing that helps a corporate analyst\n",
        "  understand the structure, economics, risks, and strategic outlook of the {user_input} industry.\n",
        "\n",
        "  STRICT RULES:\n",
        "  - Use ONLY information explicitly contained in the CONTEXT below.\n",
        "  - Every factual statement MUST end with at least one clickable citation in this format: [SOURCE X](URL).\n",
        "  - Do NOT include assumptions, estimates, or forward-looking claims unless directly supported by the sources.\n",
        "  - Avoid generic business statements that could apply to most industries.\n",
        "  - If a topic is not covered in the sources, explicitly state: \"Not covered in sources.\"\n",
        "\n",
        "  WRITING STYLE:\n",
        "  - Professional, neutral, and analytical.\n",
        "  - Focus on industry mechanisms, not definitions.\n",
        "  - Prioritize insights that matter for corporate strategy and risk assessment.\n",
        "\n",
        "  REPORT STRUCTURE:\n",
        "\n",
        "  1. Industry Overview\n",
        "    Briefly describe what the industry does, its core economic function, and why it matters\n",
        "    in the broader economy (2–3 sentences).\n",
        "\n",
        "  2. Market Structure & Value Chain\n",
        "    Explain how value is created and captured in the industry.\n",
        "    Identify key participants (e.g. producers, intermediaries, regulators, customers)\n",
        "    and how they interact.\n",
        "\n",
        "  3. Industry Scale & Geographic Footprint\n",
        "    Describe the industry’s global or regional scale, major operating regions,\n",
        "    and any notable geographic concentration patterns.\n",
        "\n",
        "  4. Competitive Landscape\n",
        "    Identify major players and explain how competition is structured\n",
        "    (e.g. fragmentation, concentration, role of incumbents vs new entrants).\n",
        "\n",
        "  5. Key Industry Drivers\n",
        "    List 3–4 concrete drivers that influence industry performance.\n",
        "    Drivers should reflect structural, regulatory, technological, or demand-side forces\n",
        "    specific to the {user_input} industry.\n",
        "\n",
        "  6. Risks, Constraints & Regulatory Barriers\n",
        "    Describe the most significant risks and constraints facing the industry,\n",
        "    including regulatory requirements, cost structures, operational risks,\n",
        "    or external pressures.\n",
        "\n",
        "  7. SWOT Analysis\n",
        "    Provide an industry-specific SWOT summary:\n",
        "    - Strengths: Structural or economic advantages unique to the industry\n",
        "    - Weaknesses: Structural limitations or inefficiencies\n",
        "    - Opportunities: Changes or trends that could materially improve industry performance\n",
        "    - Threats: External or internal forces that could materially harm the industry\n",
        "    Each point must be grounded in the provided sources and avoid generic statements.\n",
        "\n",
        "  8. Industry Outlook\n",
        "    Summarize how the industry is expected to evolve based on current trends\n",
        "    described in the sources (2–3 sentences).\n",
        "\n",
        "  LENGTH:\n",
        "  Maximum 500 words.\n",
        "\n",
        "  CONTEXT:\n",
        "  {context}\n",
        "  \"\"\")\n",
        "\n",
        "  report = (report_prompt | llm).invoke({\n",
        "      \"context\": context_text,\n",
        "      \"user_input\": user_input\n",
        "  })\n",
        "\n",
        "\n",
        "  print(\"\\n\" + \"=\"*60 + f\"\\nREPORT: {user_input.upper()}\\n\" + \"=\"*60 + f\"\\n{report.content}\")\n",
        "\n",
        "  # This tells Python to execute the function when you run the script\n",
        "if __name__ == \"__main__\":\n",
        "    generate_industry_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ado0RGY9v946",
        "outputId": "e6a27e1d-c9c5-4b55-942f-42382a4db1b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter industry: fmcg\n",
            "--------------- VERIFIED SOURCES ---------------\n",
            "1. Fast-moving consumer goods\n",
            "   URL: https://en.wikipedia.org/wiki/Fast-moving_consumer_goods\n",
            "2. Durable good\n",
            "   URL: https://en.wikipedia.org/wiki/Durable_good\n",
            "3. Clothing industry\n",
            "   URL: https://en.wikipedia.org/wiki/Clothing_industry\n",
            "4. FMCG in India\n",
            "   URL: https://en.wikipedia.org/wiki/FMCG_in_India\n",
            "5. Girteka\n",
            "   URL: https://en.wikipedia.org/wiki/Girteka\n",
            "\n",
            "============================================================\n",
            "REPORT: FMCG\n",
            "============================================================\n",
            "**1. Industry Overview**\n",
            "The FMCG industry produces and distributes fast-moving consumer goods, such as packaged foods, beverages, toiletries, and cosmetics, which are sold quickly and at a relatively low cost [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods). The industry plays a significant role in the broader economy, with its products being a part of daily consumer spending [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods). The FMCG industry is a subset of the consumer packaged goods (CPG) industry [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods).\n",
            "\n",
            "**2. Market Structure & Value Chain**\n",
            "The FMCG industry's value chain involves producers, intermediaries, regulators, and customers [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods). Producers manufacture the goods, while intermediaries, such as retailers and distributors, facilitate the movement of goods from producers to customers [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods). Regulators, such as government agencies, oversee the industry to ensure compliance with laws and regulations [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods). Customers, including individual consumers and businesses, purchase the goods [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods).\n",
            "\n",
            "**3. Industry Scale & Geographic Footprint**\n",
            "The FMCG industry has a significant global presence, with major operating regions including Europe, Asia, and the Americas [SOURCE 4](https://en.wikipedia.org/wiki/FMCG_in_India). In India, the FMCG industry is the fourth largest sector in the economy, with a projected growth rate of 27.9% CAGR by 2020 [SOURCE 4](https://en.wikipedia.org/wiki/FMCG_in_India). The industry has a notable geographic concentration pattern, with urban settings dominating the market with a 55% revenue share [SOURCE 4](https://en.wikipedia.org/wiki/FMCG_in_India).\n",
            "\n",
            "**4. Competitive Landscape**\n",
            "The FMCG industry is characterized by a large number of players, including global and local companies [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods). The industry is highly competitive, with companies competing on factors such as price, quality, and distribution [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods). New entrants, such as online retailers, are also changing the competitive landscape [SOURCE 4](https://en.wikipedia.org/wiki/FMCG_in_India).\n",
            "\n",
            "**5. Key Industry Drivers**\n",
            "The FMCG industry is driven by several key factors, including:\n",
            "* Increased population of working women [SOURCE 4](https://en.wikipedia.org/wiki/FMCG_in_India)\n",
            "* Increased disposable income and growing per capita expenditure [SOURCE 4](https://en.wikipedia.org/wiki/FMCG_in_India)\n",
            "* Growing demand for convenience and online shopping [SOURCE 4](https://en.wikipedia.org/wiki/FMCG_in_India)\n",
            "* Advances in logistics and transportation, such as temperature-controlled cargo transportation [SOURCE 5](https://en.wikipedia.org/wiki/Girteka)\n",
            "\n",
            "**6. Risks, Constraints & Regulatory Barriers**\n",
            "The FMCG industry faces several risks and constraints, including:\n",
            "* High inventory turnover and rapid consumption, which can lead to supply chain disruptions [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods)\n",
            "* Low contribution margins, which can make it challenging for companies to maintain profitability [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods)\n",
            "* Regulatory requirements, such as food safety and labeling regulations [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods)\n",
            "\n",
            "**7. SWOT Analysis**\n",
            "The FMCG industry has several strengths, weaknesses, opportunities, and threats:\n",
            "* Strengths: high demand for FMCG products, extensive distribution networks [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods)\n",
            "* Weaknesses: low contribution margins, high inventory turnover [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods)\n",
            "* Opportunities: growing demand for online shopping, increasing disposable income [SOURCE 4](https://en.wikipedia.org/wiki/FMCG_in_India)\n",
            "* Threats: intense competition, regulatory changes [SOURCE 1](https://en.wikipedia.org/wiki/Fast-moving_consumer_goods)\n",
            "\n",
            "**8. Industry Outlook**\n",
            "The FMCG industry is expected to continue growing, driven by increasing demand for convenience, online shopping, and growing disposable income [SOURCE 4](https://en.wikipedia.org/wiki/FMCG_in_India). The industry is also expected to evolve, with companies adopting new technologies and strategies to stay competitive [SOURCE 5](https://en.wikipedia.org/wiki/Girteka). Not covered in sources: specific predictions for the industry's future growth or trends.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_industry_report():\n",
        "    user_input = input(\"\\nEnter the industry for research: \").strip()\n",
        "\n",
        "    # STEP 1: Combined Gatekeeper & Query Expansion\n",
        "    setup_prompt = f\"\"\"\n",
        "    Analyze the term: '{user_input}'\n",
        "    Task 1: Is this a valid industry sector? (YES/NO)\n",
        "    Task 2: Provide a Wikipedia search query focusing on the 'Industry Overview'.\n",
        "    Format response EXACTLY: VALID: [YES/NO] | QUERY: [Your Query]\n",
        "    \"\"\"\n",
        "    setup_data = llm.invoke(setup_prompt).content.strip()\n",
        "\n",
        "    if \"VALID: NO\" in setup_data:\n",
        "        print(f\"[ALERT] {setup_data}\")\n",
        "        return\n",
        "\n",
        "    refined_search = setup_data.split(\"QUERY: \")[1]\n",
        "    print(f\"Refining search to: {refined_search}\")\n",
        "\n",
        "    # --- STEP 2: Wikipedia Search + FILTER (The Bouncer) ---\n",
        "    print(f\"[STEP 2] Fetching & Filtering Wikipedia results...\")\n",
        "    # Fetch 10 results to have a larger pool to filter from\n",
        "    raw_titles = wikipedia.search(refined_search, results=10)\n",
        "\n",
        "    # The Filter Prompt: Pick only the truly relevant business titles\n",
        "    # More efficient version:\n",
        "    filter_prompt = f\"\"\"\n",
        "    {user_input}.\n",
        "    List: {raw_titles}.\n",
        "    Pick top 5 business-relevant titles. Return ONLY comma-separated strings.\n",
        "    From this list of Wikipedia titles, return ONLY 5 sources that are about the business sector,\n",
        "    market structure, or global industry overview.\n",
        "    EXCLUDE: Individual companies, news events, biographies, or unrelated industries.\n",
        "\n",
        "    Titles: {raw_titles}\n",
        "\n",
        "    Return ONLY the selected titles, separated by commas.\n",
        "    \"\"\"\n",
        "    filtered_titles_str = llm.invoke(filter_prompt).content.strip()\n",
        "    filtered_titles = [t.strip() for t in filtered_titles_str.split(\",\") if t.strip()]\n",
        "\n",
        "    print(f\"Verified Sources: {filtered_titles}\")\n",
        "\n",
        "    # Now download only the verified content\n",
        "    urls = []\n",
        "    context_text = \"\"\n",
        "    for title in filtered_titles:\n",
        "        try:\n",
        "            page = wikipedia.page(title, auto_suggest=False)\n",
        "            urls.append(page.url)\n",
        "            context_text += f\"SOURCE: {page.url}\\nCONTENT: {page.summary}\\n\\n\"\n",
        "        except: continue\n",
        "\n",
        "    if not context_text:\n",
        "        print(\"No valid industry sources found after filtering.\")\n",
        "        return\n",
        "\n",
        "    # --- STEP 3: Report Generation ---\n",
        "    print(\"Generating report...\")\n",
        "    report_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "    ROLE: Market Research Assistant.\n",
        "    TASK: Write an industry report using ONLY the provided context.\n",
        "    Based on your reasoning, structure the report that makes the most sense for business report.\n",
        "    Including general industry overview, potential opportunities, drivers, threats, barriers, etc.\n",
        "    LENGTH: Strictly under 500 words.\n",
        "\n",
        "    CONTEXT:\n",
        "    {context}\n",
        "    \"\"\")\n",
        "\n",
        "    chain = report_prompt | llm\n",
        "    report = chain.invoke({\"context\": context_text})\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"Industry Report: {user_input.upper()}\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "    print(report.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_industry_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLL5n79HViwb",
        "outputId": "728140e7-5b4f-42e0-81c0-d2d455649b4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter the industry for research: healthcare\n",
            "\n",
            "[STEP 2] Discovering top 5 authoritative sources...\n",
            "\n",
            "--------------- VERIFIED SOURCES FOUND ---------------\n",
            "[1] https://en.wikipedia.org/wiki/Providence_Health_%26_Services\n",
            "[2] https://en.wikipedia.org/wiki/Universal_Health_Services\n",
            "[3] https://en.wikipedia.org/wiki/Healthcare_industry\n",
            "[4] https://en.wikipedia.org/wiki/United_States_Department_of_Health_and_Human_Services\n",
            "[5] https://en.wikipedia.org/wiki/Clalit_Health_Services\n",
            "------------------------------------------------------\n",
            "\n",
            "[STEP 3] Synthesizing report using these 5 verified sources...\n",
            "\n",
            "============================================================\n",
            "FINAL REPORT: HEALTHCARE\n",
            "============================================================\n",
            "\n",
            "**Strategic Report: Healthcare Industry Analysis**\n",
            "\n",
            "The healthcare industry is a complex and multifaceted sector that encompasses various services, products, and finance (Source: https://en.wikipedia.org/wiki/Healthcare_industry). In the United States, the industry is one of the largest and fastest-growing, consuming over 10% of the country's gross domestic product (GDP) (Source: https://en.wikipedia.org/wiki/Healthcare_industry).\n",
            "\n",
            "**Key Players**\n",
            "\n",
            "Providence Health & Services is a not-for-profit Catholic healthcare system that operates 51 hospitals and over 1,100 clinics in seven U.S. states (Source: https://en.wikipedia.org/wiki/Providence_Health_%26_Services). Universal Health Services, Inc. (UHS) is a Fortune 500 company that provides hospital and healthcare services, with total revenues of $15.8 billion in 2024 (Source: https://en.wikipedia.org/wiki/Universal_Health_Services).\n",
            "\n",
            "**Regulatory Environment**\n",
            "\n",
            "The United States Department of Health and Human Services (HHS) is a cabinet-level executive branch department that sets guidelines for the private healthcare system and provides essential human services (Source: https://en.wikipedia.org/wiki/United_States_Department_of_Health_and_Human_Services). The department has undergone significant changes, including the establishment of the Affordable Care Act and the reorganization of various agencies.\n",
            "\n",
            "**International Perspective**\n",
            "\n",
            "Clalit Health Services is the largest health service organization in Israel, providing medical care to over 4.6 million insured members (Source: https://en.wikipedia.org/wiki/Clalit_Health_Services). The organization operates 14 hospitals and over 1,300 primary care clinics, and has invested heavily in health information technology.\n",
            "\n",
            "**Data Gaps**\n",
            "\n",
            "* Financial data for Providence Health & Services\n",
            "* Detailed information on UHS's international operations\n",
            "* Impact of regulatory changes on the healthcare industry\n",
            "* Comparative analysis of healthcare systems in different countries\n",
            "\n",
            "**Conclusion**\n",
            "\n",
            "The healthcare industry is a complex and dynamic sector that requires careful analysis and strategic planning. Understanding the key players, regulatory environment, and international perspective is crucial for making informed decisions. However, there are significant data gaps that need to be addressed to provide a comprehensive understanding of the industry.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set system prompt\n",
        "system_prompt = \"\"\"\n",
        "Your are a market research assistant, when the user asks for a specific industry,\n",
        "please gather the top 5 relevant pages from Wikipedia and condense them into a report in less than 500 words,\n",
        "if you can not find information on the specific industry, ask the user to update the information.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Mf6pNMX3kPUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipedia\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import time\n",
        "\n",
        "# Initialize with built-in retries to handle the 429 error\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-3-flash-preview\", temperature=0.2, max_retries=5)\n",
        "\n",
        "def generate_industry_report():\n",
        "    user_input = input(\"Enter the industry for research: \").strip()\n",
        "\n",
        "    # ONE CALL for both Validation and Expansion\n",
        "    setup_prompt = f\"\"\"\n",
        "    Analyze the term: '{user_input}'\n",
        "    1. Is this a valid industry sector? (YES/NO)\n",
        "    2. If YES, provide a 3-word Wikipedia search query to get a strategic overview.\n",
        "    Format: VALID: [YES/NO] | QUERY: [Query]\n",
        "    \"\"\"\n",
        "    setup_response = llm.invoke(setup_prompt).text.strip()\n",
        "\n",
        "    if \"VALID: NO\" in setup_response:\n",
        "        print(\"Invalid industry. Please try again.\")\n",
        "        return generate_industry_report()\n",
        "\n",
        "    refined_query = setup_response.split(\"QUERY: \")[1]\n",
        "    print(f\"Refining search to: {refined_query}\")\n",
        "\n",
        "    # Step 2: Search\n",
        "    search_results = wikipedia.search(refined_query, results=5)\n",
        "    context_text = \"\"\n",
        "    for title in search_results:\n",
        "        try:\n",
        "            page = wikipedia.page(title, auto_suggest=False)\n",
        "            context_text += f\"SOURCE: {page.url}\\nCONTENT: {page.content[:3000]}\\n\\n\"\n",
        "        except: continue\n",
        "\n",
        "    # A small delay to let the Rate Limit \"breathe\"\n",
        "    time.sleep(2)\n",
        "\n",
        "    # --- STEP 3: Strategic Report Generation (< 500 words) ---\n",
        "    print(\"\\n[STEP 3] Synthesizing strategic report...\")\n",
        "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "    ROLE: Senior Business Analyst.\n",
        "    TASK: Write a strategic industry report based ONLY on the provided Wikipedia context.\n",
        "    Use professional 'Investment' terminology and cite URL headings for each section.\n",
        "    LENGTH: Strictly under 500 words.\n",
        "\n",
        "    STRUCTURE:\n",
        "    1. Executive Summary: Current industry state.\n",
        "    2. Market Pillars: Key technologies or economic drivers (cite URLs).\n",
        "    3. Strategic Risks: Barriers to entry or obsolescence threats.\n",
        "    4. Data Gaps: What critical business info is missing from these sources?\n",
        "\n",
        "    CONTEXT:\n",
        "    {context}\n",
        "    \"\"\")\n",
        "\n",
        "    chain = prompt | llm\n",
        "    report = chain.invoke({\"context\": context_text})\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"MARKET RESEARCH REPORT: {user_input.upper()}\")\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "    print(report.text)\n",
        "\n",
        "# Run the assistant\n",
        "if __name__ == \"__main__\":\n",
        "    generate_industry_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "DwwLP-_3M5W0",
        "outputId": "cea53992-065e-4156-d08a-33188f9ea224"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the industry for research: healthcare\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ChatGoogleGenerativeAIError",
          "evalue": "Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 18.947830933s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '18s'}]}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   3046\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3047\u001b[0;31m             response: GenerateContentResponse = self.client.models.generate_content(\n\u001b[0m\u001b[1;32m   3048\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5226\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5227\u001b[0;31m       response = self._generate_content(\n\u001b[0m\u001b[1;32m   5228\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparsed_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36m_generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   4008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4009\u001b[0;31m     response = self._api_client.request(\n\u001b[0m\u001b[1;32m   4010\u001b[0m         \u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     )\n\u001b[0;32m-> 1386\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m     response_body = (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mretry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtenacity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRetrying\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mretry_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_once\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mexc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mretry_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_attempt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_request_once\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m   1198\u001b[0m       )\n\u001b[0;32m-> 1199\u001b[0;31m       \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m       return HttpResponse(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/errors.py\u001b[0m in \u001b[0;36mraise_for_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/genai/errors.py\u001b[0m in \u001b[0;36mraise_error\u001b[0;34m(cls, status_code, response_json, response)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClientError\u001b[0m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 18.947830933s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '18s'}]}}",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mChatGoogleGenerativeAIError\u001b[0m               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2540628319.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Run the assistant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mgenerate_industry_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2540628319.py\u001b[0m in \u001b[0;36mgenerate_industry_report\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mFormat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVALID\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mYES\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mNO\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mQUERY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mQuery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \"\"\"\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0msetup_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetup_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"VALID: NO\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msetup_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[1;32m   2533\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2535\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m     def _get_ls_params(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m             cast(\n\u001b[1;32m    401\u001b[0m                 \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                 self.generate_prompt(\n\u001b[0m\u001b[1;32m    403\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1120\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                 results.append(\n\u001b[0;32m--> 931\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    932\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1234\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   3049\u001b[0m             )\n\u001b[1;32m   3050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClientError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3051\u001b[0;31m             \u001b[0m_handle_client_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_response_to_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_handle_client_error\u001b[0;34m(e, request)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"unknown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Error calling model '{model_name}' ({e.status}): {e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mChatGoogleGenerativeAIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mChatGoogleGenerativeAIError\u001b[0m: Error calling model 'gemini-3-flash-preview' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 18.947830933s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '18s'}]}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sources = []\n",
        "for i, doc in enumerate(docs, start=1):\n",
        "    sources.append(\n",
        "        f\"Source {i}: {doc.metadata['title']}\\n{doc.page_content}\"\n",
        "    )\n",
        "\n",
        "context = \"\\n\\n\".join(sources)\n"
      ],
      "metadata": {
        "id": "Zz6FxtosvFPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# 1. The Dynamic System Persona\n",
        "system_behavior = \"\"\"ROLE: Strategic Market Research Assistant.\n",
        "TASK: Synthesize the provided data into a professional Industry Report.\n",
        "\n",
        "GROUNDING RULES:\n",
        "1. THEMATIC STRUCTURE: Do not use a fixed template. Create 3-5 custom sections based on the natural patterns found in the sources.\n",
        "2. EVIDENCE ONLY: Use ONLY the provided context. If data (like financials or future projections) is missing, do not invent it.\n",
        "3. CITATIONS: Every claim must include the source URL in parentheses.\n",
        "4. TONE: Professional, objective, and analytical.\"\"\"\n",
        "\n",
        "# 2. Your Retrieval Output (Placeholder for your Wikipedia results)\n",
        "context_for_ai = context  # This is where your 5 Wikipedia docs go\n",
        "\n",
        "# 3. The Combined Gemma/Gemini-safe Message\n",
        "messages = [\n",
        "    HumanMessage(content=f\"{system_behavior}\\n\\nSOURCES TO ANALYZE:\\n{context_for_ai}\\n\\nFINAL INSTRUCTION: Organize the report by identifying the most significant 'Market Pillars' found in these specific texts.\")\n",
        "]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "BfoEsjnMvLBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37e799fa-688a-410f-e6dc-b37778f95439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Industry Report: The Global Solar Energy Market\n",
            "\n",
            "## 1. Technological Evolution and Efficiency Milestones\n",
            "The solar industry has transitioned from a 19th-century scientific observation to a primary global energy source. The photovoltaic (PV) effect was first observed by Edmond Becquerel in 1839, with the first commercial solar cell created by Charles Fritts in 1881 (Source 1). However, modern solar technology is largely based on the 1939 design by Russell Ohl, which Bell Labs utilized in 1954 to create the first commercially viable silicon solar cell (Source 1, Source 2).\n",
            "\n",
            "Efficiency has been a primary driver of technological development, particularly in specialized sectors:\n",
            "*   **Terrestrial Systems:** Standard PV systems utilize solar modules consisting of PV cells made from semiconducting materials that produce direct current (DC) electricity (Source 1, Source 5).\n",
            "*   **Space Applications:** The need for lightweight, high-performance power for satellites like Vanguard 1 (1958) pushed efficiency from early 1%–6% levels to approximately 10% (Source 2). Modern space-grade multi-junction gallium arsenide (GaAs) cells now achieve roughly 30% efficiency (Source 2).\n",
            "*   **System Components:** Beyond the panels, modern \"smart modules\" and systems incorporate inverters (to convert DC to AC), power optimizers, and trackers to maximize energy absorption (Source 1, Source 5).\n",
            "\n",
            "## 2. Economic Drivers and Market Scaling\n",
            "The solar market has experienced exponential growth, with worldwide PV usage evolving from a niche application to a mainstream electricity source between 1992 and 2023 (Source 1). By the end of 2022, global cumulative installed capacity reached approximately 1,185 gigawatts (GW), supplying over 6% of global electricity demand (Source 1).\n",
            "\n",
            "Key economic factors include:\n",
            "*   **Cost Reduction:** The cost of solar PV electricity has fallen by 85% since 2010 (Source 1). Module prices specifically dropped by about 90% during the 2010s (Source 5).\n",
            "*   **Policy and Investment:** Growth has been supported by government initiatives, such as Germany’s \"one hundred thousand roof program\" in 2000 and massive Chinese investment in production capacity to achieve economies of scale (Source 5).\n",
            "*   **Competitive Pricing:** In 2023, the International Energy Agency (IEA) declared solar PV the \"cheapest source of electricity in history,\" with some bids in high-resource regions like Qatar reaching as low as 0.015 US$/kWh (Source 5).\n",
            "\n",
            "## 3. Diversified Application Models\n",
            "Solar technology is no longer limited to traditional rooftop or ground-mounted arrays. The industry is diversifying into specialized \"dual-use\" and extreme-environment applications:\n",
            "*   **Agrivoltaics:** This involves the dual use of land for solar energy and agriculture. Systems can be installed between crops, elevated above them, or on greenhouse roofs (Source 3). While panels can help retain moisture and lower temperatures for leafy greens or spices, they require trade-offs for sun-intensive staple crops like wheat and rice (Source 3).\n",
            "*   **Spacecraft Power:** In the inner Solar System, PV panels are the primary power source for sensors, telemetry, and electric propulsion (Source 2). Key metrics for this sector include \"specific power\" (watts per mass) and \"stowed packing efficiency\" (Source 2).\n",
            "*   **Floatovoltaics and Solar Canals:** Placing solar arrays on bodies of water or infrastructure can reduce evaporation losses and improve panel efficiency through evaporative cooling (Source 3).\n",
            "*   **Active vs. Passive Solar:** Market applications also distinguish between active techniques (PV, concentrated solar power) and passive techniques (architectural design, thermal mass) (Source 4).\n",
            "\n",
            "## 4. Environmental Impact and Resource Management\n",
            "Solar energy is recognized as an essential renewable resource that enhances energy security and reduces greenhouse gas emissions compared to hydrocarbons (Source 1, Source 4). The Earth receives approximately 174 petawatts (PW) of solar radiation; capturing energy from just 0.3% of the Earth's total land area (roughly the size of Sweden or California) could theoretically meet all human energy needs (Source 4).\n",
            "\n",
            "However, the industry faces specific constraints and requirements:\n",
            "*   **Material Constraints:** While silicon is abundant, other materials required for manufacturing, such as silver, may constrain future growth (Source 5).\n",
            "*   **Operational Disadvantages:** Solar energy is variable and depends on sunlight intensity, requiring cleaning and the integration of energy storage systems or high-voltage distribution lines to balance the grid (Source 1, Source 5).\n",
            "*   **Land Use Competition:** As capacity grows, competition for land use remains a major constraint, driving the development of agrivoltaics and other co-location strategies (Source 3, Source 5).\n"
          ]
        }
      ]
    }
  ]
}